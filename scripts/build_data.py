import sys
import argparse
from pathlib import Path
import pandas as pd

# ThÃªm parent folder vÃ o sys.path Ä‘á»ƒ import src
sys.path.append(str(Path(__file__).resolve().parent.parent))

import json
from openpyxl import load_workbook
from src.extractor import extract_links
from src.downloader import download_file, sanitize_filename
from src.parser import parse_docx_file
from src.sheet_parser import parse_xlsx_file, parse_worksheet
from src.aggregator import aggregate_by_student, save_json, print_summary


# ============ DEFAULT PATHS ============
DEFAULT_EXCEL = Path("data/danhsachct.xlsx")

# Paths (sáº½ Ä‘Æ°á»£c set trong main dá»±a vÃ o arguments)
EXCEL_PATH = DEFAULT_EXCEL
DOWNLOAD_DIR = Path("data/downloaded")
RAW_OUTPUT = Path("data/raw_activities.json")
FINAL_OUTPUT = Path("data/students.json")


def process_external_link(display_text: str, url: str, index: int) -> dict:
    """Download vÃ  parse external link (Google Docs/Sheets)."""
    print(f"\n{'='*60}")
    print(f"ğŸŒ [{index}] {display_text[:50]}...")
    
    filename = sanitize_filename(f"{index:03d}_{display_text}")
    file_path = DOWNLOAD_DIR / filename
    
    print(f"â¬‡ï¸  Downloading...")
    success, file_ext = download_file(url, file_path)
    
    if not success:
        print(f"âŒ Download failed!")
        return {'error': 'Download failed', 'url': url, 'students': []}
    
    actual_path = file_path.with_suffix(f'.{file_ext}')
    
    print(f"ğŸ” Parsing ({file_ext})...")
    if file_ext == 'xlsx':
        activity_name, students = parse_xlsx_file(actual_path, url)
    else:
        activity_name, students = parse_docx_file(actual_path, url)
    
    print(f"âœ… {activity_name[:40]}... | {len(students)} sinh viÃªn")
    
    return {
        'activity_name': activity_name,
        'activity_link': url,
        'student_count': len(students),
        'students': students
    }


def process_internal_link(workbook, sheet_name: str, display_text: str, url: str, index: int) -> dict:
    """Parse internal link (sheet trong cÃ¹ng file Excel)."""
    print(f"\n{'='*60}")
    print(f"ğŸ“‘ [{index}] {display_text[:50]}...")
    
    if sheet_name not in workbook.sheetnames:
        print(f"âŒ Sheet khÃ´ng tá»“n táº¡i: {sheet_name}")
        return {'error': 'Sheet not found', 'students': []}
    
    worksheet = workbook[sheet_name]
    activity_name = sheet_name
    
    print(f"ğŸ” Parsing sheet: {sheet_name[:40]}...")
    students = parse_worksheet(worksheet, activity_name, activity_link=url)
    
    print(f"âœ… {activity_name[:40]}... | {len(students)} sinh viÃªn")
    
    return {
        'activity_name': activity_name,
        'activity_link': url,  # Giá»¯ link gá»‘c
        'student_count': len(students),
        'students': students
    }


def step1_extract_and_parse(limit: int | None) -> list:
    """BÆ°á»›c 1: Extract links vÃ  parse (há»— trá»£ cáº£ external vÃ  internal)."""
    print("\n" + "="*60)
    print("ğŸ“¥ BÆ¯á»šC 1: EXTRACT & PARSE")
    print("="*60)
    
    DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)
    
    # Extract links
    print(f"\nğŸ“‚ Äá»c file Excel: {EXCEL_PATH}")
    links = extract_links(EXCEL_PATH, limit=limit)
    
    # Count link types
    external_count = sum(1 for l in links if l['link_type'] == 'external')
    internal_count = sum(1 for l in links if l['link_type'] == 'internal')
    
    print(f"âœ… TÃ¬m tháº¥y {len(links)} links:")
    print(f"   ğŸŒ External (Google): {external_count}")
    print(f"   ğŸ“‘ Internal (Sheet):  {internal_count}")
    if limit:
        print(f"   (giá»›i háº¡n {limit})")
    
    # Load workbook má»™t láº§n cho internal links
    wb = load_workbook(EXCEL_PATH) if internal_count > 0 else None
    
    # Process tá»«ng link
    results = []
    for idx, link_info in enumerate(links, 1):
        if link_info['link_type'] == 'external':
            result = process_external_link(
                link_info['display_text'], 
                link_info['url'], 
                idx
            )
        else:
            result = process_internal_link(
                wb,
                link_info['sheet_name'],
                link_info['display_text'],
                link_info['url'],
                idx
            )
        results.append(result)
    
    if wb:
        wb.close()
    
    # LÆ°u raw data
    print(f"\nğŸ’¾ LÆ°u raw data: {RAW_OUTPUT}")
    RAW_OUTPUT.parent.mkdir(parents=True, exist_ok=True)
    with open(RAW_OUTPUT, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    total_students = sum(r.get('student_count', 0) for r in results)
    print(f"ğŸ“Š Tá»•ng: {len(results)} chÆ°Æ¡ng trÃ¬nh | {total_students} records")
    
    return results


def step2_aggregate(raw_data: list) -> dict:
    """BÆ°á»›c 2: Gom nhÃ³m theo MSSV."""
    print("\n" + "="*60)
    print("ğŸ”„ BÆ¯á»šC 2: AGGREGATE THEO MSSV")
    print("="*60)
    
    # Flatten students tá»« raw_data
    all_students = []
    for activity in raw_data:
        all_students.extend(activity.get('students', []))
    
    if not all_students:
        print("âš ï¸ KhÃ´ng cÃ³ sinh viÃªn nÃ o!")
        return {}
    
    df = pd.DataFrame(all_students)
    print(f"ğŸ“‹ DataFrame: {len(df)} rows")
    
    result = aggregate_by_student(df)
    
    # Summary
    print_summary(df, result)
    
    # LÆ°u final data
    print(f"\nğŸ’¾ LÆ°u final data: {FINAL_OUTPUT}")
    save_json(result, FINAL_OUTPUT)
    
    return result


def main():
    global EXCEL_PATH, DOWNLOAD_DIR, RAW_OUTPUT, FINAL_OUTPUT
    
    parser = argparse.ArgumentParser(
        description="Build NRL data: Extract â†’ Parse â†’ Aggregate"
    )
    parser.add_argument(
        '-l', '--limit',
        type=int,
        default=None,
        help='Sá»‘ lÆ°á»£ng links xá»­ lÃ½ (máº·c Ä‘á»‹nh: táº¥t cáº£)'
    )
    parser.add_argument(
        '-e', '--excel',
        type=Path,
        default=DEFAULT_EXCEL,
        help=f'File Excel input (máº·c Ä‘á»‹nh: {DEFAULT_EXCEL})'
    )
    args = parser.parse_args()
    
    # Set paths dá»±a vÃ o file Excel
    EXCEL_PATH = args.excel
    if args.excel != DEFAULT_EXCEL:
        excel_name = args.excel.stem  # e.g. "2023-2024"
        DOWNLOAD_DIR = Path(f"data/downloaded_{excel_name}")
        RAW_OUTPUT = Path(f"data/raw_{excel_name}.json")
        FINAL_OUTPUT = Path(f"data/students_{excel_name}.json")
    
    print("ğŸš€ NRL DATA BUILDER")
    print("="*60)
    print(f"   ğŸ“‚ Excel:  {EXCEL_PATH}")
    print(f"   ğŸ“‚ Output: {FINAL_OUTPUT}")
    print(f"   ğŸ”¢ Limit:  {args.limit if args.limit else 'ALL'}")
    
    # BÆ°á»›c 1: Extract & Parse
    raw_data = step1_extract_and_parse(args.limit)
    
    # BÆ°á»›c 2: Aggregate
    final_data = step2_aggregate(raw_data)
    
    # HoÃ n táº¥t
    print("\n" + "="*60)
    print("âœ… HOÃ€N Táº¤T!")
    print("="*60)
    print(f"   ğŸ“ Raw data:   {RAW_OUTPUT}")
    print(f"   ğŸ“ Final data: {FINAL_OUTPUT}")
    print(f"   ğŸ‘¥ Sinh viÃªn:  {len(final_data)}")


if __name__ == "__main__":
    main()
