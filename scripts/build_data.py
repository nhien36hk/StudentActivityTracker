"""
Script xá»­ lÃ½ dá»¯ liá»‡u NRL: Download tá»« Google Docs â†’ Parse â†’ Aggregate.

Usage:
    python scripts/build_data.py                              # File máº·c Ä‘á»‹nh
    python scripts/build_data.py --limit 5                    # Test 5 links
    python scripts/build_data.py --excel data/2023-2024.xlsx  # File Excel khÃ¡c
    
Example:
    python scripts/build_data.py --excel data/2023-2024.xlsx
    # Output tá»± Ä‘á»™ng: data/students_2023-2024.json
"""
import sys
import argparse
from pathlib import Path

# ThÃªm parent folder vÃ o sys.path Ä‘á»ƒ import src
sys.path.append(str(Path(__file__).resolve().parent.parent))

import json
from src.extractor import extract_hyperlinks
from src.downloader import download_docx, sanitize_filename
from src.parser import parse_docx_file
from src.aggregator import load_to_dataframe, aggregate_by_student, save_json, print_summary


# ============ DEFAULT PATHS ============
DEFAULT_EXCEL = Path("data/danhsachct.xlsx")

# Paths (sáº½ Ä‘Æ°á»£c set trong main dá»±a vÃ o arguments)
EXCEL_PATH = DEFAULT_EXCEL
DOWNLOAD_DIR = Path("data/downloaded")
RAW_OUTPUT = Path("data/raw_activities.json")
FINAL_OUTPUT = Path("data/students.json")


def process_single_link(display_text: str, url: str, index: int) -> dict:
    """Download vÃ  parse má»™t link."""
    print(f"\n{'='*60}")
    print(f"ğŸ“„ [{index}] {display_text[:50]}...")
    
    # Táº¡o tÃªn file
    filename = sanitize_filename(f"{index:03d}_{display_text}")
    if not filename.endswith('.docx'):
        filename += '.docx'
    file_path = DOWNLOAD_DIR / filename
    
    # Download
    print(f"â¬‡ï¸  Downloading...")
    success = download_docx(url, file_path)
    
    if not success:
        print(f"âŒ Download failed!")
        return {'error': 'Download failed', 'url': url, 'students': []}
    
    # Parse
    print(f"ğŸ” Parsing...")
    activity_name, students = parse_docx_file(file_path, url)
    
    print(f"âœ… {activity_name[:40]}... | {len(students)} sinh viÃªn")
    
    return {
        'activity_name': activity_name,
        'activity_link': url,
        'student_count': len(students),
        'students': students
    }


def step1_download_and_parse(limit: int | None) -> list:
    """BÆ°á»›c 1: Download táº¥t cáº£ files vÃ  parse."""
    print("\n" + "="*60)
    print("ğŸ“¥ BÆ¯á»šC 1: DOWNLOAD & PARSE")
    print("="*60)
    
    DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)
    
    # Extract links
    print(f"\nğŸ“‚ Äá»c file Excel: {EXCEL_PATH}")
    links = extract_hyperlinks(EXCEL_PATH, limit=limit)
    total = len(links)
    print(f"âœ… TÃ¬m tháº¥y {total} links" + (f" (giá»›i háº¡n {limit})" if limit else ""))
    
    # Process tá»«ng link
    results = []
    for idx, (display_text, url) in enumerate(links, 1):
        result = process_single_link(display_text, url, idx)
        results.append(result)
    
    # LÆ°u raw data
    print(f"\nğŸ’¾ LÆ°u raw data: {RAW_OUTPUT}")
    RAW_OUTPUT.parent.mkdir(parents=True, exist_ok=True)
    with open(RAW_OUTPUT, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    total_students = sum(r.get('student_count', 0) for r in results)
    print(f"ğŸ“Š Tá»•ng: {len(results)} chÆ°Æ¡ng trÃ¬nh | {total_students} records")
    
    return results


def step2_aggregate(raw_data: list) -> dict:
    """BÆ°á»›c 2: Gom nhÃ³m theo MSSV."""
    print("\n" + "="*60)
    print("ğŸ”„ BÆ¯á»šC 2: AGGREGATE THEO MSSV")
    print("="*60)
    
    # Flatten students tá»« raw_data
    all_students = []
    for activity in raw_data:
        all_students.extend(activity.get('students', []))
    
    if not all_students:
        print("âš ï¸ KhÃ´ng cÃ³ sinh viÃªn nÃ o!")
        return {}
    
    # Convert to DataFrame vÃ  aggregate
    import pandas as pd
    df = pd.DataFrame(all_students)
    print(f"ğŸ“‹ DataFrame: {len(df)} rows")
    
    result = aggregate_by_student(df)
    
    # Summary
    print_summary(df, result)
    
    # LÆ°u final data
    print(f"\nğŸ’¾ LÆ°u final data: {FINAL_OUTPUT}")
    save_json(result, FINAL_OUTPUT)
    
    return result


def main():
    global EXCEL_PATH, DOWNLOAD_DIR, RAW_OUTPUT, FINAL_OUTPUT
    
    parser = argparse.ArgumentParser(
        description="Build NRL data: Download â†’ Parse â†’ Aggregate"
    )
    parser.add_argument(
        '-l', '--limit',
        type=int,
        default=None,
        help='Sá»‘ lÆ°á»£ng links xá»­ lÃ½ (máº·c Ä‘á»‹nh: táº¥t cáº£)'
    )
    parser.add_argument(
        '-e', '--excel',
        type=Path,
        default=DEFAULT_EXCEL,
        help=f'File Excel input (máº·c Ä‘á»‹nh: {DEFAULT_EXCEL})'
    )
    args = parser.parse_args()
    
    # Set paths dá»±a vÃ o file Excel
    EXCEL_PATH = args.excel
    if args.excel != DEFAULT_EXCEL:
        excel_name = args.excel.stem  # e.g. "2023-2024"
        DOWNLOAD_DIR = Path(f"data/downloaded_{excel_name}")
        RAW_OUTPUT = Path(f"data/raw_{excel_name}.json")
        FINAL_OUTPUT = Path(f"data/students_{excel_name}.json")
    
    print("ğŸš€ NRL DATA BUILDER")
    print("="*60)
    print(f"   ğŸ“‚ Excel:  {EXCEL_PATH}")
    print(f"   ğŸ“‚ Output: {FINAL_OUTPUT}")
    print(f"   ğŸ”¢ Limit:  {args.limit if args.limit else 'ALL'}")
    
    # BÆ°á»›c 1: Download & Parse
    raw_data = step1_download_and_parse(args.limit)
    
    # BÆ°á»›c 2: Aggregate
    final_data = step2_aggregate(raw_data)
    
    # HoÃ n táº¥t
    print("\n" + "="*60)
    print("âœ… HOÃ€N Táº¤T!")
    print("="*60)
    print(f"   ğŸ“ Raw data:   {RAW_OUTPUT}")
    print(f"   ğŸ“ Final data: {FINAL_OUTPUT}")
    print(f"   ğŸ‘¥ Sinh viÃªn:  {len(final_data)}")


if __name__ == "__main__":
    main()

